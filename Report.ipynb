{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ddpg-algorithm]: https://user-images.githubusercontent.com/3620840/119758155-ee57d600-be5a-11eb-8b19-59fab595fbe1.png \"DDPG Algorithm\"\n",
    "[reinforcement-learning]: https://user-images.githubusercontent.com/3620840/114342627-0379df00-9b11-11eb-83d5-cc2773145c8c.jpg \"Reinforcement Learning\"\n",
    "[mc-control]: https://user-images.githubusercontent.com/3620840/114350423-08915b00-9b1e-11eb-8cf4-9eb2abd72a33.png \"MC Control\"\n",
    "\n",
    "\n",
    "\n",
    "# Project description\n",
    "\n",
    "This project uses deep reinforcement learning to teach a double jointed arm to move to a target location. The goal is achieve by using Deep Reinforcement Learning. More especifically, we use an Actor-Critic based algorithm called [Deep Deterministic Policy Gradient (DDPG)](https://arxiv.org/pdf/1509.02971.pdf).\n",
    "\n",
    "The global parameters for the training are specified in the file agent.py and copied here for simplicity.\n",
    "\n",
    "## Parameters\n",
    "\n",
    "```\n",
    "BUFFER_SIZE = int(1e5)  # replay buffer size\n",
    "BATCH_SIZE = 128        # minibatch size\n",
    "GAMMA = 0.99            # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "LR_ACTOR = 1e-3         # learning rate of the actor \n",
    "LR_CRITIC = 1e-3        # learning rate of the critic\n",
    "WEIGHT_DECAY = 0        # L2 weight decay\n",
    "```\n",
    "\n",
    "## Reinforcement Learning\n",
    "\n",
    "In Reinforcement Learning, in a given instant in time, an agent gets its current state $s$ and based on it decides on an action $a$ to take. After taking the action, the agent gets a reward $r_{t+1}$ and its state changes to $s_{t+1}$. The reward and the new state of the agent depend on the current state and the action that was selected. This process is sintetized in the formula and image below.\n",
    "\n",
    "$$(s_t, a_t) => (r_{t+1}, s_{t+1})$$\n",
    "\n",
    "![Reinforcement learning][reinforcement-learning]\n",
    "\n",
    "The goal of the agent is to choose a set of actions that will lead to the biggest cumulative return. The cumulative return is the sum of all the rewards collected by the agent while performing the actions and switching states. The cumulative return the agent gets is calculated as below.\n",
    "\n",
    "$$G_t = R_{t + 1} + R_{t + 2} + R_{t + 3} + R_{t + 4} + ... + R_{t + n}$$\n",
    "\n",
    "One problem of calculating the cumulative return this way is that a reward in the future is as valuable as a reward now. The agent should rely more on its more reliable closest rewards than the ones far in the future. To achieve that, we can introduce a discount factor `GAMMA` $\\gamma$ to decrease the weight of future rewards. The new discounted cumulative return is calculated as follows.\n",
    "\n",
    "$$G_t = R_{t + 1} + \\gamma R_{t + 2} + \\gamma^2 R_{t + 3} + \\gamma^3 R_{t + 4} + ... + \\gamma^{n-1} R_{t + n}$$\n",
    "\n",
    "The value of $\\gamma$ should be between 0 and 1. If set to 0, all future rewards are not taken into account and the agent only considers its most imediate reward. On the other extreme, setting $\\gamma$ to 1, this equation turns back to its inital form where it considers imediate rewards as valuable as future rewards.\n",
    "\n",
    "The agent choses the actions based on a policy:\n",
    "$$\\pi(s) => a$$\n",
    "\n",
    "The policy maps a state to an action. One way to implement the policy is to maintain a Q-table with size (# states) x (# actions). Each entry on the table represents the expected cumulative future return the agent gets if it takes an action $a$ given it is on state $s$. This value can be accessed on the Q-Table\\[state\\]\\[action\\]. The expected cumulative future return corresponds to the sum of the imediate reward the agent gets from taking action $a$ while on state $s$ plus the expected reward from ending up on state $s_{t + 1}$ and choose the next actions following the policy $\\pi$.\n",
    "\n",
    "$$(s, a) => (r, s')$$\n",
    "\n",
    "$$Q(s, a) = r + Q(s_{t + 1}, \\pi(s_{t + 1}))$$\n",
    "\n",
    "\n",
    "## Deep Reinforcement Learning (Actor-Critic Based Method)\n",
    "\n",
    "As the name suggests, an Actor-Critic agent is composed by an actor network and a critic network.\n",
    "\n",
    "### Actor\n",
    "\n",
    "The actor implements a policy based reinforcement learning method. This means that the actor aims to approximate the optimal policy directly. Given the current state of the agent, the actor outputs the best action to take. It can be represented by the function:\n",
    "\n",
    "$$\\mu(s;\\theta^u)$$\n",
    "\n",
    "where $\\theta_u$are the parameters of the actor neural network.\n",
    "\n",
    "### Critic\n",
    "\n",
    "The critic implements a value based reinforcement learning method. This means that the critic aims to approximate the expected cumulative return. It gets as input the current state of the agent and an action and outputs the expected cumulative return of that state, action pair. It can be represented by the function:\n",
    "\n",
    "$$Q(s, \\mu(s;\\theta^u); \\theta^Q)$$\n",
    "\n",
    "where $\\theta_Q$are the parameters of the critic neural network.\n",
    "\n",
    "### Training\n",
    "\n",
    "To train both the agent and the critic, this algorithm uses a [Experience Replay Buffer](http://files.davidqiu.com//research/nature14236.pdf) of size `BUFFER_SIZE`. At each step `BATCH_SIZE` memories are randomly selected from the buffer and used to update the parameters of both networks.\n",
    "\n",
    "It is important to notice that this algorithm uses two separate networks with distinct parameters both for the actor and the critic. This gives us a total of 4 different sets of parameters that are $\\theta^u$ (local actor), $\\theta^{u^i}$ (target actor), $\\theta^Q$ (local critic), $\\theta^{Q^i}$ (target critic). After training the local networks with the experiences from the replay buffer, a soft update of the target networks is performed. In this case, a soft copy is used and controlled by the TAU parameter. The bigger the value of  ùúè  (up to 1), the closer the local and the target network get after the soft update. This process of using two separate networks is used to increase the stability of the training step by fixing the target network while updating the local network. This method if fully described on the [Deep Q-Network](http://files.davidqiu.com//research/nature14236.pdf) article.\n",
    "\n",
    "The full [DDPG training algorithm](https://arxiv.org/pdf/1509.02971.pdf) is described below.\n",
    "\n",
    "![DDPG Algorithm][ddpg-algorithm]\n",
    "\n",
    "### Model\n",
    "\n",
    "This project uses two Fully Connected Neural Networks for both the actor and the critic. \n",
    "\n",
    "The actor is a FCNN with input size `state_size`, followed by two hidden layers of size 128. A `relu` function is used on the output of each of the three first layers. The output layer has size `action_size`. All the actions range from -1 to 1, so we chose to use a `tanh` activation function on the output layer.\n",
    "\n",
    "The critic input layer is implemented following the description of the DDPG paper. It first has an input layer of size `state_size`. The difference here is that the first hidden layer receives as input the output of the input layer plus the action vector, which makes it have size `128 + action_size`. The output of the first hidden layer is then used as input for the second hidden layer without modifications. After each of the first three layers, a `relu` function is used. The critic output layer has size 1, which corresponds to the expected cumulative return for the (state, action) pair provided as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(data, size):\n",
    "    return np.convolve(data, np.ones(size), mode='valid') / size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ddpg reached goal on episode 132\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = ['ddpg']\n",
    "\n",
    "plot_size = 200\n",
    "goal = 30\n",
    "maintain_goal_for = 100\n",
    "\n",
    "for model_name in models:\n",
    "    scores_file_path = os.path.join('checkpoints', f'score_{model_name}.pkl')\n",
    "    scores = np.array(pickle.load(open(scores_file_path, 'rb'))[:plot_size])\n",
    "    \n",
    "    goal_index = np.where(scores > goal)[0]\n",
    "    goal_average = moving_average(np.diff(goal_index), maintain_goal_for)\n",
    "    goal_maintained = np.where(goal_average == 1)[0]\n",
    "    if goal_index.any() and goal_maintained.any():\n",
    "        print(f'{model_name} reached goal on episode {goal_index[0] + goal_maintained[0] + maintain_goal_for + 1}')\n",
    "    else:\n",
    "        print(f'{model_name} did not reach the goal')\n",
    "    \n",
    "    plt.plot(range(len(scores)), scores, label=model_name)\n",
    "\n",
    "plt.hlines(goal, 0, plot_size, color='black', linestyles='dashed')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Above you can see the score achived by the agent at each time step during training. This results use the version 2 of the environment where 20 agents are present. At each time step the rewards coming from each agent are averaged over the number of agents. The agent was able to first achieve the goal of +30 reward at the step 32 and maintained itself above this threshold until the end of the training at step 200. The environment is considered complete when the agent is able to maintain a score of +30 for at least 100 consecutive episodes, which happened at the episode 132."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work\n",
    "\n",
    "There is an improvement over the `UniformReplayBuffer` that was used to train the models above called [Prioritized Experience Replay](https://arxiv.org/abs/1511.05952) (PER). In this second method, the experiences are sampled using a priority proportional to their TD-error.\n",
    "\n",
    "One improvement descrived in the [DDPG paper](https://arxiv.org/pdf/1509.02971.pdf) is to use batch normalization, This technique standardizes the input batch which can help stabilize the training.\n",
    "\n",
    "This project could be further improved by implementing [Twin-Delayed DDPG (TD3)](https://arxiv.org/pdf/1802.09477.pdf). This algorithm offers that introduces state-of-the-art improvements to DDPG. There are also other algorithms like [Distributed Distributional Deterministic Policy Gradients (D4PG)](https://openreview.net/forum?id=SyZipzbCb) and [Trust Region Policy Optimization (TRPO)](https://arxiv.org/abs/1502.05477) that have shown better results than DDPG in other environments.\n",
    "\n",
    "Also, a benchmark of Deep Reinforcement methods for Continuous Control can be accessed [here](https://arxiv.org/abs/1604.06778)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
